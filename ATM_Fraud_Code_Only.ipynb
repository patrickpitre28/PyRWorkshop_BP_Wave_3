{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': 'iam-ServiceId-8f959616-4d92-4073-bbf2-1d3f4f6ffad0',\n",
    "    'iam_service_endpoint': 'https://iam.bluemix.net/oidc/token',\n",
    "    'api_key': 'VYkxc-7ohgrp0zdnHRSHAQW-aqI5m-b6j8K3YBllfR4a'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_1e498447d5f74cd6b90b92b35bb6514e_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "data = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('ATM_CleanData.csv', 'datascienceinbanking-donotdelete-pr-hrnb5icgks2da6'))\n",
    "data.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasDF=data.toPandas()\n",
    "pandasDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed('Day of Week','DAY_OF_WEEK')\n",
    "data = data.withColumnRenamed('Time of Day','TIME_OF_DAY')\n",
    "data = data.withColumnRenamed('Time of Day Band','TIME_OF_DAY_BAND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brunel\n",
    "%brunel data('pandasDF') treemap x(DAY_OF_WEEK,TIME_OF_DAY_BAND) color(DAY_OF_WEEK) size(FRAUD) sum(FRAUD) tooltip(#all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "chartsize": "50",
      "handlerId": "barChart",
      "keyFields": "TIME_OF_DAY",
      "rendererId": "matplotlib",
      "rowCount": "500",
      "title": "Fraudulent Transactions per Hour",
      "valueFields": "FRAUD"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pixiedust.display import *\n",
    "display(pandasDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, IndexToString\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "SI1 = StringIndexer(inputCol='ATM_POSI', outputCol='positionEncoded')\n",
    "SI2 = StringIndexer(inputCol='POST_COD_Region',outputCol='regionEncoded')\n",
    "SI3 = StringIndexer(inputCol='DAY_OF_WEEK',outputCol='dayOfWeekEncoded')\n",
    "SI4 = StringIndexer(inputCol='TIME_OF_DAY_BAND',outputCol='timeOfDayEncoded')\n",
    "labelIndexer = StringIndexer(inputCol='FRAUD', outputCol='label').fit(data)\n",
    "\n",
    "OH1 = OneHotEncoder(inputCol=\"positionEncoded\", outputCol=\"positionEncoded\"+\"classVec\")\n",
    "OH2 = OneHotEncoder(inputCol=\"regionEncoded\", outputCol=\"regionEncoded\"+\"classVec\")\n",
    "OH3 = OneHotEncoder(inputCol=\"dayOfWeekEncoded\", outputCol=\"dayOfWeekEncoded\"+\"classVec\")\n",
    "OH4 = OneHotEncoder(inputCol=\"timeOfDayEncoded\", outputCol=\"timeOfDayEncoded\"+\"classVec\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"positionEncoded\"+\"classVec\", \"regionEncoded\"+\"classVec\", \"dayOfWeekEncoded\"+\"classVec\", \"timeOfDayEncoded\"+\"classVec\"],\\\n",
    "                            outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf=RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "pipeline = Pipeline(stages=[SI1,SI2,SI3,SI4,labelIndexer,OH1,OH2,OH3,OH4,assembler,rf,labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, test = data.randomSplit([0.8,0.2], seed=6)\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.transform(test)\n",
    "results=results.select(results[\"label\"],results[\"prediction\"],results[\"FRAUD\"],results['predictedLabel'],results[\"probability\"])\n",
    "results.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model precision:' + format(results.filter(results.label == results.prediction).count() / float(results.count())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "print ('Area under ROC curve = .' + format(evaluator.evaluate(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 with Spark",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
