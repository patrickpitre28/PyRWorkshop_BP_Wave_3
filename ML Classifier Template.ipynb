{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat Call Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from clustering import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def tokenize(doc):\n",
    "    doc = doc.translate(translator)\n",
    "    return doc.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process \n",
    "# df['tokens'] = preproc_driver(df['doc'])\n",
    "df['tokens'] = df['doc'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy import interp\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn_pandas import DataFrameMapper, gen_features, CategoricalImputer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, stratify=df['Call Order'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Call Order'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Call Order'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# trained fasttext embeddings\n",
    "embeddings = FastText.load_fasttext_format('./vectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !unzip wiki.en.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_pretrained = FastText.load_fasttext_format('./wiki.en.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !unzip glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# glove2word2vec(glove_input_file=\"glove.42B.300d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "embeddings_glove_pretrained = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "class TfidfWeightedEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Returns a TfIdf weighted embedding.\n",
    "        Input is tokenized docs\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings):\n",
    "        self.model = embeddings\n",
    "        self.embedding_dim = embeddings.wv.vector_size\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.dictionary = Dictionary(X)\n",
    "        self.corpus = [self.dictionary.doc2bow(doc) for doc in X]\n",
    "        self.tfidf = TfidfModel(self.corpus, id2word=self.dictionary)\n",
    "        # self.corpus_tfidf = self.tfidf[self.corpus]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        tfidf_vectors = []\n",
    "        for i, sent in enumerate(X):\n",
    "            sent_bow = self.dictionary.doc2bow(sent)\n",
    "            sent_tfidf = self.tfidf[sent_bow]\n",
    "            vec = self.tfidf_word_vectors(sent_tfidf, sent)\n",
    "            tfidf_vectors.append(vec)\n",
    "        return np.array(tfidf_vectors)\n",
    "    \n",
    "    def tfidf_word_vectors(self, tfidf_scores, tokens):\n",
    "        doc_dict = dict(tfidf_scores)\n",
    "        n = len(tokens)\n",
    "        res = np.zeros(self.embedding_dim)\n",
    "        if n == 0:\n",
    "            return res\n",
    "        for token in tokens:\n",
    "            if token in self.dictionary.token2id and token in self.model.wv:\n",
    "                res += doc_dict[self.dictionary.token2id[token]] * 100 * self.model.wv[token]\n",
    "        return res/n\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        names = ['embeddingDim{}'.format(i) for i in range(100)]\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def identity_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=identity_fun,\n",
    "    preprocessor=identity_fun,\n",
    "    token_pattern=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_def = gen_features(\n",
    "        columns=['PLAN', 'PRODUCT_LINE', 'Location', 'REGIONCODE', 'nvcDialedNumber'],\n",
    "        classes=[{'class': CategoricalImputer, 'missing_values': -1}]\n",
    "    )\n",
    "\n",
    "feature_def.extend([\n",
    "    ('tokens', tfidf),\n",
    "    (['CSR_Tenure_months'], Imputer())\n",
    "])\n",
    "\n",
    "mapper = DataFrameMapper(feature_def, df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_def2 = gen_features(\n",
    "        columns=['PLAN', 'PRODUCT_LINE', 'Location', 'REGIONCODE', 'nvcDialedNumber'],\n",
    "        classes=[{'class': CategoricalImputer, 'missing_values': -1}]\n",
    "    )\n",
    "\n",
    "feature_def2.extend([\n",
    "    ('tokens', TfidfWeightedEmbeddings(embeddings_glove_pretrained)),\n",
    "    (['CSR_Tenure_months'], Imputer())\n",
    "])\n",
    "\n",
    "mapper2 = DataFrameMapper(feature_def2, df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_undersample(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    df_call0 = df[df['Call Order'] == 0].sample(n=y.value_counts()[1], random_state=42)\n",
    "    df_call1 = df[df['Call Order'] == 1]\n",
    "    df_undersample = pd.concat([df_call0, df_call1])\n",
    "    # Shuffle\n",
    "    df_undersample = df_undersample.sample(frac=1)\n",
    "    assert df_undersample['Call Order'].value_counts()[0] == df_undersample['Call Order'].value_counts()[1]\n",
    "    new_X = df_undersample.iloc[:, :-1]\n",
    "    new_y = df_undersample.iloc[:, -1]\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_oversample(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    df_call1 = df[df['Call Order'] == 1].sample(n=y.value_counts()[0], replace=True, random_state=42)\n",
    "    df_call0 = df[df['Call Order'] == 0]\n",
    "    df_oversample = pd.concat([df_call0, df_call1])\n",
    "    # Shuffle\n",
    "    df_oversample = df_oversample.sample(frac=1)\n",
    "    assert df_oversample['Call Order'].value_counts()[0] == df_oversample['Call Order'].value_counts()[1]\n",
    "    new_X = df_oversample.iloc[:, :-1]\n",
    "    new_y = df_oversample.iloc[:, -1]\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_roc_pr_curves(y_test, prob, xgb_model=False):\n",
    "    if not xgb_model:\n",
    "        prob = prob[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    p, r, thre = precision_recall_curve(y_test, prob)\n",
    "    average_p = average_precision_score(y_test, prob)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.set_xlim([-0.05,1.05])\n",
    "    ax1.set_ylim([-0.05,1.05])\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.set_title('ROC Curve')\n",
    "\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.set_xlim([-0.05,1.05])\n",
    "    ax2.set_ylim([-0.05,1.05])\n",
    "    ax2.set_xlabel('Recall')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.set_title('PR Curve')\n",
    "    ax1.plot(fpr, tpr, lw=1, label='Area under ROC Curve = %0.2f'%roc_auc)\n",
    "    ax2.plot(r, p, lw=1, label='Area under PR Curve = %0.2f'%average_p)\n",
    "    ax1.legend(loc='lower right')    \n",
    "    ax2.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc, average_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_cm(y_test, pred):\n",
    "    conf_mat = confusion_matrix(y_test, pred)\n",
    "    df_cm = pd.DataFrame(conf_mat, index=target_names, columns=target_names)\n",
    "    fig, ax = plt.subplots(figsize=(4,3))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", ax=ax)\n",
    "    ax.set_ylabel('True label');\n",
    "    ax.set_xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = ['Non-Repeat', 'Repeat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_meta = df_train.copy()\n",
    "\n",
    "train_meta['xgb'] = np.zeros(train_meta.shape[0])\n",
    "train_meta['lr'] = np.zeros(train_meta.shape[0])\n",
    "train_meta['rf'] = np.zeros(train_meta.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_meta = df_test.copy()\n",
    "\n",
    "test_meta['xgb_avg'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['xgb_fold_0'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['xgb_fold_1'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['xgb_fold_2'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['xgb_fold_3'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['xgb_fold_4'] = np.zeros(test_meta.shape[0])\n",
    "\n",
    "test_meta['lr_avg'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['lr_fold_0'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['lr_fold_0'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['lr_fold_0'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['lr_fold_0'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['lr_fold_0'] = np.zeros(test_meta.shape[0])\n",
    "\n",
    "test_meta['rf_avg'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['rf_fold_0'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['rf_fold_1'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['rf_fold_2'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['rf_fold_3'] = np.zeros(test_meta.shape[0])\n",
    "test_meta['rf_fold_4'] = np.zeros(test_meta.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_kfold_cv(df_train, df_test, mapper, clf, n_splits=5, mode='original', feat_imp=False, name='model_1'):\n",
    "    kf = StratifiedKFold(n_splits=n_splits, random_state=42)\n",
    "    X_train = df_train.drop(['Call Order'], axis=1)\n",
    "    y_train = df_train['Call Order']\n",
    "\n",
    "    X_test = df_test.drop(['Call Order'], axis=1)\n",
    "    y_test = df_test['Call Order']\n",
    "\n",
    "    test_pred = np.zeros((X_test.shape[0]))\n",
    "\n",
    "    accuracies = []\n",
    "    rocs = []\n",
    "    prs = []\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        print('_'*100)\n",
    "        print('#'*26)\n",
    "        print('###### Doing Fold {} ######'.format(i))\n",
    "        print('#'*26)\n",
    "        X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        # Resampling\n",
    "        if mode == 'undersample':\n",
    "            X_train_kf, y_train_kf = do_undersample(X_train_kf, y_train_kf)\n",
    "        elif mode == 'oversample':\n",
    "            X_train_kf, y_train_kf = do_oversample(X_train_kf, y_train_kf)\n",
    "        print('X_train_kf shape: ', X_train_kf.shape)\n",
    "        print('X_val_kf shape: ', X_val_kf.shape)\n",
    "        # Fit\n",
    "        clf.fit(mapper.fit_transform(X_train_kf), y_train_kf)\n",
    "        val_pred = clf.predict(mapper.transform(X_val_kf))\n",
    "        val_probas = clf.predict_proba(mapper.transform(X_val_kf))\n",
    "        train_meta.loc[train_meta.iloc[val_index].index, name] = val_probas[:, 1]\n",
    "\n",
    "        test_probas = clf.predict_proba(mapper.transform(X_test))[:, 1]\n",
    "        test_meta[name + '_fold_{}'.format(i)] = test_probas\n",
    "        test_pred += test_probas\n",
    "        # Print model metrics\n",
    "        print('Accuracy: ', accuracy_score(y_val_kf, val_pred))\n",
    "        accuracies.append(accuracy_score(y_val_kf, val_pred))\n",
    "        print('Classification Report: ')\n",
    "        print(classification_report(y_val_kf, val_pred))\n",
    "        # Plot confusion matrix \n",
    "        plot_cm(y_val_kf, val_pred)\n",
    "        # Compute ROC curve and area the curve\n",
    "        roc_auc_fold, pr_fold = plot_roc_pr_curves(y_val_kf, val_probas)\n",
    "        rocs.append(roc_auc_fold)\n",
    "        prs.append(pr_fold)\n",
    "        \n",
    "        if feat_imp:\n",
    "            fig, ax = plt.subplots(figsize=(7,5))\n",
    "            plot_importance(clf, ax=ax, max_num_features=30)\n",
    "\n",
    "    test_pred /= n_splits\n",
    "    test_meta[name + '_avg'] = test_pred\n",
    "    print('_'*100)\n",
    "    print('#'*24)\n",
    "    print('####### RESULTS #######')\n",
    "    print('#'*24)\n",
    "    print('Mean Accuracy over 5 folds: {0:.4f}, Std: {1:.4f}'.format(np.mean(accuracies), np.std(accuracies)))\n",
    "    print('Mean AUCROC over 5 folds: {0:.4f}, Std: {1:.4f}'.format(np.mean(rocs), np.std(rocs)))\n",
    "    print('Mean AUPRC over 5 folds: {0:.4f}, Std: {1:.4f}'.format(np.mean(prs), np.std(prs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_total_train_test(df_train, df_test, mapper, clf, mode='original', name='model_1'):\n",
    "    X_train = df_train.drop(['Call Order'], axis=1)\n",
    "    y_train = df_train['Call Order']\n",
    "    \n",
    "    X_test = df_test.drop(['Call Order'], axis=1)\n",
    "    y_test = df_test['Call Order']\n",
    "    \n",
    "    print('X_train shape: ', X_train.shape)\n",
    "    print('X_test shape: ', X_test.shape)\n",
    "\n",
    "    clf.fit(mapper.fit_transform(X_train), y_train)\n",
    "    pred = clf.predict(mapper.transform(X_test))\n",
    "    probas_ = clf.predict_proba(mapper.transform(X_test))\n",
    "    test_meta.loc[:, name] = probas_[:, 1]\n",
    "    # Print model metrics\n",
    "    print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "    print('Classification Report: ')\n",
    "    print(classification_report(y_test, pred))\n",
    "    # Plot confusion matrix \n",
    "    plot_cm(y_test, pred)\n",
    "    # Compute ROC curve and area the curve\n",
    "    roc_auc_fold, pr_fold = plot_roc_pr_curves(y_test, probas_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_kfold_cv(df_train, df_test, mapper2, LogisticRegression(C=0.1, class_weight='balanced'), name='lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_kfold_cv(df_train, df_test, mapper2, RandomForestClassifier(n_estimators=100, max_depth=3, min_samples_split=10, class_weight='balanced', n_jobs=-1), name='rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TFIDF encoding\n",
    "mapper3 = DataFrameMapper([\n",
    "                ('tokens', tfidf),\n",
    "            ], df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TFIDF weighted average of Fasttext trained embeddings\n",
    "mapper4 = DataFrameMapper([\n",
    "                ('tokens', TfidfWeightedEmbeddings(embeddings)),\n",
    "            ], df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TFIDF weighted average of Fasttext pre-trained embeddings\n",
    "mapper5 = DataFrameMapper([\n",
    "                ('tokens', TfidfWeightedEmbeddings(embeddings_pretrained)),\n",
    "            ], df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF weighted average of GloVe pre-trained embeddings\n",
    "mapper6 = DataFrameMapper([\n",
    "                ('tokens', TfidfWeightedEmbeddings(embeddings_glove_pretrained)),\n",
    "            ], df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF weighted average of Fasttext trained embeddings and PCA\n",
    "mapper7 = DataFrameMapper([\n",
    "                ('tokens', [TfidfWeightedEmbeddings(embeddings), PCA(n_components=20)]),\n",
    "            ], df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF weighted average of GloVe pre-trained embeddings and PCA\n",
    "mapper8 = DataFrameMapper([\n",
    "                ('tokens', [TfidfWeightedEmbeddings(embeddings_glove_pretrained), PCA(n_components=20)]),\n",
    "            ], df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def do_kfold_cv_xgb(df_train, df_test, mapper, params, num_boost_round, early_stopping_rounds, n_splits=5, \n",
    "                    mode='original', verbose_eval=True, feat_imp=True, name='model_xgb'):\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=n_splits, random_state=42)\n",
    "    X_train = df_train.drop(['Call Order'], axis=1)\n",
    "    y_train = df_train['Call Order']\n",
    "    \n",
    "    X_test = df_test.drop(['Call Order'], axis=1)\n",
    "    y_test = df_test['Call Order']\n",
    "\n",
    "    test_pred = np.zeros((X_test.shape[0]))\n",
    "\n",
    "    accuracies = []\n",
    "    rocs = []\n",
    "    prs = []\n",
    "    best_ntrees = []\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        print('_'*100)\n",
    "        print('#'*26)\n",
    "        print('###### Doing Fold {} ######'.format(i))\n",
    "        print('#'*26)\n",
    "        X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        if mode == 'undersample':\n",
    "            X_train_kf, y_train_kf = do_undersample(X_train_kf, y_train_kf)\n",
    "        elif mode == 'oversample':\n",
    "            X_train_kf, y_train_kf = do_oversample(X_train_kf, y_train_kf)\n",
    "        print('X_train_kf shape: ', X_train_kf.shape)\n",
    "        print('X_val_kf shape: ', X_val_kf.shape)\n",
    "        \n",
    "        d_train_kf = xgb.DMatrix(mapper.fit_transform(X_train_kf), label=y_train_kf)\n",
    "        d_val_kf = xgb.DMatrix(mapper.transform(X_val_kf), label=y_val_kf)\n",
    "\n",
    "        d_test = xgb.DMatrix(mapper.transform(X_test), label=y_test)\n",
    "        \n",
    "        bst = xgb.train(params, d_train_kf, num_boost_round=num_boost_round,\n",
    "                            evals=[(d_train_kf, 'train'),( d_val_kf, 'val')], \n",
    "                            verbose_eval=verbose_eval,\n",
    "                            early_stopping_rounds=early_stopping_rounds,\n",
    "                            )\n",
    "\n",
    "        train_pred = bst.predict(d_train_kf, ntree_limit=bst.best_ntree_limit)        \n",
    "        val_pred = bst.predict(d_val_kf, ntree_limit=bst.best_ntree_limit)\n",
    "        pred = bst.predict(d_test, ntree_limit=bst.best_ntree_limit)\n",
    "        test_meta[name + '_fold_{}'.format(i)] = pred\n",
    "        test_pred += pred\n",
    "\n",
    "        train_meta.loc[train_meta.iloc[val_index].index, name] = val_pred\n",
    "        # Print model metrics\n",
    "        if not verbose_eval:\n",
    "            print('Best tree limit: ', bst.best_ntree_limit)\n",
    "            print('Train AUROC: {}'.format(roc_auc_score(y_train_kf, train_pred)), \\\n",
    "                  'Val AUROC: {}'.format(roc_auc_score(y_val_kf, val_pred)))\n",
    "            \n",
    "        roc_auc_fold, pr_fold = plot_roc_pr_curves(y_val_kf, val_pred, xgb_model=True)\n",
    "        rocs.append(roc_auc_fold)\n",
    "        prs.append(pr_fold)\n",
    "        best_ntrees.append(bst.best_ntree_limit)\n",
    "        \n",
    "        if feat_imp:\n",
    "            fig, ax = plt.subplots(figsize=(7,5))\n",
    "            plot_importance(bst, ax=ax, max_num_features=30)\n",
    "            \n",
    "    test_pred /= n_splits\n",
    "    test_meta[name + '_avg'] = test_pred\n",
    "    print('_'*100)\n",
    "    print('#'*24)\n",
    "    print('####### RESULTS #######')\n",
    "    print('#'*24)\n",
    "    print('Mean AUCROC over 5 folds: {0:.4f}, Std: {1:.4f}'.format(np.mean(rocs), np.std(rocs)))\n",
    "    print('Mean AUPRC over 5 folds: {0:.4f}, Std: {1:.4f}'.format(np.mean(prs), np.std(prs)))\n",
    "    # print('Best tree limits: {}, Mean: {:.4f}'.format(best_ntrees, np.mean(best_ntrees)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FastText trained and PCA\n",
    "params = {\n",
    "    'booster':'gbtree',\n",
    "    'eta':0.000001,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread':4,\n",
    "    'min_child_weight': 30,\n",
    "    'subsample': 0.8,\n",
    "    'max_depth':3,\n",
    "    'lambda':2\n",
    "#     'scale_pos_weight':7804.0/1150.0\n",
    "}\n",
    "\n",
    "num_boost_round = 2000\n",
    "early_stopping_rounds = 50\n",
    "    \n",
    "do_kfold_cv_xgb(df_train, mapper7, params, num_boost_round, early_stopping_rounds, name='xgb_fasttext_pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe and PCA\n",
    "params = {\n",
    "    'booster':'gbtree',\n",
    "    'eta':0.000001,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread':4,\n",
    "    'min_child_weight': 30,\n",
    "    'subsample': 0.8,\n",
    "    'max_depth':3,\n",
    "    'lambda':2\n",
    "#     'scale_pos_weight':7804.0/1150.0\n",
    "}\n",
    "\n",
    "num_boost_round = 2000\n",
    "early_stopping_rounds = 50\n",
    "    \n",
    "do_kfold_cv_xgb(df_train, df_test, mapper8, params, num_boost_round, early_stopping_rounds, name='xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_total_train_test_xgb(df_train, df_test, mapper8, params, best_num_boost_round, name='xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster':'gbtree',\n",
    "    'eta':0.000001,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread':4,\n",
    "    'min_child_weight': 30,\n",
    "    'subsample': 0.8,\n",
    "    'max_depth':3,\n",
    "    'lambda':2#,\n",
    "#     'scale_pos_weight':7804.0/1150.0\n",
    "}\n",
    "\n",
    "num_boost_round = 2000\n",
    "early_stopping_rounds = 50\n",
    "    \n",
    "best_num_boost_round = do_kfold_cv_xgb(df_train, mapper5, params, num_boost_round, early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_total_train_test(df_train, df_test, mapper5, params, best_num_boost_round, name='xgb_model_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_stacked = train_meta[['xgb', 'lr', 'rf', 'Call Order']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_stacked = test_meta[['xgb_avg', 'lr_avg', 'rf_avg', 'Call Order']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_stacked.columns = ['xgb', 'lr', 'rf', 'Call Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_stacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapper_identity = DataFrameMapper([], df_out=True, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(df_test_stacked['Call Order'], df_test_stacked['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(df_test_stacked['Call Order'], df_test_stacked['rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(df_test_stacked['Call Order'], df_test_stacked['xgb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_total_train_test(df_train_stacked, df_test_stacked, mapper_identity, LogisticRegression(), name='stacked_lr_xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_stacked = test_meta.iloc[:, -19:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_stacked.to_csv('../datasets/df_train_stacking_orig.csv', index=False)\n",
    "all_test_stacked.to_csv('../datasets/df_test_stacking_orig.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developed by Data Science Elite Team, IBM Analytics:\n",
    "- Vinay Rao Dandin, Data Scientist\n",
    "\n",
    "#### Copyright (c) 2018 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
