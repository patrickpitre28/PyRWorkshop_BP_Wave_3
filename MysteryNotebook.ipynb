{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'IAM_SERVICE_ID': 'iam-ServiceId-8f959616-4d92-4073-bbf2-1d3f4f6ffad0',\n",
    "    'IBM_API_KEY_ID': 'VYkxc-7ohgrp0zdnHRSHAQW-aqI5m-b6j8K3YBllfR4a',\n",
    "    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.bluemix.net/oidc/token',\n",
    "    'BUCKET': 'datascienceinbanking-donotdelete-pr-hrnb5icgks2da6',\n",
    "    'FILE': 'MysteryData.csv'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': 'iam-ServiceId-8f959616-4d92-4073-bbf2-1d3f4f6ffad0',\n",
    "    'iam_service_endpoint': 'https://iam.bluemix.net/oidc/token',\n",
    "    'api_key': 'VYkxc-7ohgrp0zdnHRSHAQW-aqI5m-b6j8K3YBllfR4a'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_1e498447d5f74cd6b90b92b35bb6514e_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "input_df = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('MysteryData.csv', 'datascienceinbanking-donotdelete-pr-hrnb5icgks2da6'))\n",
    "input_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_index = 'CustID'\n",
    "item_feature = 'Stocks'\n",
    "item_features = ['Tech','Auto','Hotel','Airline','Energy','Biotech','Pharma','Utilities','Financials','Staples','Industrials']\n",
    "\n",
    "if item_features:\n",
    "    group_items_df = input_df.select([group_index] + item_features)\n",
    "else:\n",
    "    group_items_df = input_df.select(group_index, item_feature).distinct()\n",
    "group_items_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value = 'Y'\n",
    "\n",
    "\n",
    "if item_features:\n",
    "\n",
    "    \n",
    "    def item_list(group):\n",
    "        item_list = []\n",
    "        for item in item_features:\n",
    "            if group[item] == true_value:\n",
    "                item_list.append(item)\n",
    "        return item_list\n",
    "\n",
    "    \n",
    "    group_items_rdd = group_items_df.rdd.map(lambda group: (group[0], item_list(group)))\n",
    "\n",
    "\n",
    "else:\n",
    "    \n",
    "    \n",
    "    group_items_rdd = group_items_df.rdd.map(lambda group: (group[0], [group[1]])).reduceByKey(lambda x,y:x+y)\n",
    "\n",
    "for row in group_items_rdd.take(20):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_item_groups_rdd = group_items_rdd.filter(lambda order: len(order[1])>1)\n",
    "\n",
    "multi_item_groups_df = multi_item_groups_rdd.toDF([group_index, item_feature])\n",
    "multi_item_groups_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "min_support=0.05\n",
    "min_confidence=0.2\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=item_feature, minSupport=min_support, minConfidence=min_confidence)\n",
    "model = fpGrowth.fit(multi_item_groups_df)\n",
    "model.freqItemsets.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.associationRules.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Watson Studio\n",
    "import brunel\n",
    "pd_associationRules = model.associationRules.toPandas()\n",
    "%brunel data('pd_associationRules') chord x(antecedent) y(consequent)  color(confidence) size(confidence) tooltip(antecedent, consequent, confidence) :: width=800, height=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%brunel data('pd_associationRules') edge color(confidence:sequential) key(antecedent, consequent) tooltip(antecedent, consequent, confidence) style('symbol:curvedArrow') + network y(antecedent, consequent) key(#values) label(#values) style('.label {font-size:10px}') \n",
    ":: width=800, height=600 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = [\"Auto\", \"Tech\"]\n",
    "\n",
    "test_data = spark.createDataFrame([(test_items, )], [item_feature])\n",
    "model.transform(test_data).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "- https://spark.apache.org/docs/2.3.0/api/python/pyspark.ml.html?highlight=associationrules#pyspark.ml.fpm.FPGrowth\n",
    "- https://github.com/apache/spark/blob/master/examples/src/main/python/ml/fpgrowth_example.py\n",
    "\n",
    "\n",
    "### Developed by Data Science Elite Team, IBM Analytics:\n",
    "\n",
    "- David Thomason - Software Engineer\n",
    "\n",
    "Copyright (c) 2018 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.5 with Spark",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
