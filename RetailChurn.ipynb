{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and verify versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "print('The pandas version is {}.'.format(pd.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'IAM_SERVICE_ID': 'iam-ServiceId-210be2d3-af5e-43b6-9d74-0427ae8ae81a',\n",
    "    'IBM_API_KEY_ID': '9FthwkkdExB6wrCH1HafvISYEZEeKAKEKpWfPg9TV2hM',\n",
    "    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.bluemix.net/oidc/token',\n",
    "    'BUCKET': 'pyrlabtest-donotdelete-pr-ecn1gj2kpu5dli',\n",
    "    'FILE': 'customers.csv'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_2 = {\n",
    "    'IAM_SERVICE_ID': 'iam-ServiceId-210be2d3-af5e-43b6-9d74-0427ae8ae81a',\n",
    "    'IBM_API_KEY_ID': '9FthwkkdExB6wrCH1HafvISYEZEeKAKEKpWfPg9TV2hM',\n",
    "    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.bluemix.net/oidc/token',\n",
    "    'BUCKET': 'pyrlabtest-donotdelete-pr-ecn1gj2kpu5dli',\n",
    "    'FILE': 'transactions.csv'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "client_b6ce1d66a23747c685affa13595b2acb = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='9FthwkkdExB6wrCH1HafvISYEZEeKAKEKpWfPg9TV2hM',\n",
    "    ibm_auth_endpoint=\"https://iam.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_b6ce1d66a23747c685affa13595b2acb.get_object(Bucket='pyrlabtest-donotdelete-pr-ecn1gj2kpu5dli',Key='customers.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "customers = pd.read_csv(body)\n",
    "customers.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = client_b6ce1d66a23747c685affa13595b2acb.get_object(Bucket='pyrlabtest-donotdelete-pr-ecn1gj2kpu5dli',Key='transactions.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "transactions = pd.read_csv(body)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows in customers = {}'.format(customers.CustomerID.count()))\n",
    "print('Number of rows in trips = {}'.format(transactions.CustomerID.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = customers.join(transactions.set_index('CustomerID'), on='CustomerID', how='inner').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows in joined = {}'.format(joined.CustomerID.count()))\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.describe()\n",
    "#Clear to see that the Monetary_score column contains data outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Frequency_score column should have been inferred as a numeric, so it may contain some unwanted non-numeric data\n",
    "joined.dtypes.filter(items=['Frequency_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force the Frequency_score column to a numeric data type as it should be\n",
    "joined[['Frequency_score']] = joined[['Frequency_score']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows with invalid data\n",
    "print('Number of rows with invalid values = {}'.format(len(joined[joined.isnull().any(axis=1)])))\n",
    "joined[joined.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with invalid data\n",
    "joined = joined.dropna(axis=0)\n",
    "print('Number of rows in joined = {}'.format(joined.CustomerID.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency_score is float data type, but should be integer\n",
    "joined.dtypes.filter(items=['Frequency_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast Frequency_score as integer\n",
    "joined[['Frequency_score']] = joined[['Frequency_score']].astype(int)\n",
    "joined.dtypes.filter(items=['Frequency_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with outliers in Monetary_score that we previously identified\n",
    "joined = joined[joined['Monetary_score'] <=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['Monetary_score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Columns not being used as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropCols = (['CustomerID', 'Invest', 'Educ', 'MARITAL', 'TimeYears', 'lasttrans', 'current', 'Monetary_score'])\n",
    "joined.drop(dropCols, axis=1, inplace=True)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert numeric data to integer (some numeric columns were inferred as float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retire column was infered as a float data type\n",
    "joined['Retire'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedColNames = joined.columns.values.tolist()\n",
    "intList = []\n",
    "numericCols = []\n",
    "for col in joinedColNames:\n",
    "    if joined[col].dtypes == 'float64' or joined[col].dtypes == 'int64':\n",
    "        numericCols.append(col)\n",
    "        intList.append('int')\n",
    "# Create a dictionary that will be used to set the numeric columns to integer type\n",
    "intDict = dict(zip(numericCols, intList))\n",
    "print(\"Show columns of integer data type\")\n",
    "intDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conert the numeric columns to integer\n",
    "joined = joined.astype(intDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All numeric data is now int64\n",
    "joined.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the Churn label calling the new column CHURN and drop the original Churn column\n",
    "le = LabelEncoder()\n",
    "joined['CHURN']= le.fit_transform(joined['Churn'])\n",
    "joined = joined.drop(['Churn'], axis = 1)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install sklearn-pandas package that will be used to endode the categorical features\n",
    "!pip install sklearn-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the LabelEncoder to encode the categorical features\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "mapper = DataFrameMapper(\n",
    "    [('Retire', None),\n",
    "     ('Mortgage', LabelEncoder()),\n",
    "     ('LOC', LabelEncoder()),\n",
    "     ('GENDER', LabelEncoder()),\n",
    "     ('CHILDREN',LabelEncoder()),\n",
    "     ('WORKING', LabelEncoder()),\n",
    "     ('HighMonVal',LabelEncoder()),\n",
    "     ('AgeRange',LabelEncoder()),\n",
    "     ('Frequency_score',None)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the label column out from the features dataframe\n",
    "X = joined.drop('CHURN', axis = 1)\n",
    "y = joined['CHURN']\n",
    "# Sample the indexed DataFrame\n",
    "X.sample(n=5, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_frame().sample(n=5, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test datasets¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the number of rows in each data set\n",
    "print('Number of rows in X_train is {}.'.format(X_train.shape[0]))\n",
    "print('Number of rows in X_test is {}.'.format(X_test.shape[0]))\n",
    "print('Number of rows in y_train is {}.'.format(y_train.shape[0]))\n",
    "print('Number of rows in y_test is {}.'.format(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGBClassifier = XGBClassifier()\n",
    "steps = [('mapper', mapper),('XGBClassifier', XGBClassifier)]\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "#model=pipeline.fit( X_train, y_train )\n",
    "\n",
    "#Train the model\n",
    "model = (pipeline.fit(X_train, y_train, XGBClassifier__eval_metric='error', \n",
    "        XGBClassifier__eval_set=[((mapper.fit_transform(X_train), y_train)),(mapper.fit_transform(X_test), y_test)]))\n",
    "\n",
    "# The eval_metric parameter specifies the evaluation metrics for validation data \n",
    "# Here we are using a Binary classification error rate. It is calculated as #(wrong cases)/#(all cases).\n",
    "# For the predictions, the evaluation will regard the instances with prediction value larger than 0.5 as positive instances,\n",
    "# and the others as negative instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model training parameters\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required modules from the scikit-learn metrics package\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "# Convert numpy array to list\n",
    "predictions = y_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy: {:.1f}%'.format(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Model - Feature Importance and Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XGBClassifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print('{0} importance = {1:.2f}'.format(X_train.columns.tolist()[x], XGBClassifier.feature_importances_[x])) for x in range(len(X_train.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and display the performance evaluation\n",
    "eval = model.named_steps['XGBClassifier'].evals_result()\n",
    "eval_steps = range(len(eval['validation_0']['error']))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, figsize=(8, 6))\n",
    "\n",
    "ax.plot(eval_steps, [1-x for x in eval['validation_0']['error']], label='Train')\n",
    "ax.plot(eval_steps, [1-x for x in eval['validation_1']['error']], label='Test')\n",
    "ax.legend()\n",
    "ax.set_title('Accuracy')\n",
    "ax.set_xlabel('Number of iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoid Overfitting By Limiting Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntree_limits the number of trees in the prediction; defaults to 0 (use all trees)\n",
    "n_trees = 10\n",
    "y_pred = model.named_steps['XGBClassifier'].predict(mapper.fit_transform(X_test), ntree_limit= n_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of the trained model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy: {:.1f}%'.format(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoid Overfitting By Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation error needs to decrease at least every <early_stopping_rounds> round(s) to continue training\n",
    "# Returns the model from the last iteration (not the best one) \n",
    "rounds = 10\n",
    "steps = [('mapper', mapper),('XGBClassifier', XGBClassifier)]\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "model = (pipeline.fit(X_train, y_train, XGBClassifier__eval_metric='error', XGBClassifier__early_stopping_rounds=rounds,\n",
    "        XGBClassifier__eval_set=[((mapper.fit_transform(X_train), y_train)),(mapper.fit_transform(X_test), y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best score\n",
    "print('Best Score: {:.3f}'.format(XGBClassifier.best_score))\n",
    "print('Best Iteration: {}'.format(XGBClassifier.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best number of trees\n",
    "print('Best Score: {}'.format(XGBClassifier.best_ntree_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of the trained model with early stopping\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy: {:.1f}%.'.format(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "# Plot the confusion matrix\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve (Logistic Regression)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out AUC, the percentage of the ROC plot that is underneath the curve\n",
    "print('AUC using XGBoost = {:.2f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import WML API\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials={\n",
    "  \"apikey\": \"iZ0kha1IQxdAI239b92utWHTkWhPdS2JwCIGH90nOIKU\",\n",
    "  \"iam_apikey_description\": \"Auto-generated for key 065ebbd2-9b64-4479-b0fe-e6c1d9054cd1\",\n",
    "  \"iam_apikey_name\": \"wdp-writer\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/d8ec35232337194375b709e39ae4e4e5::serviceid:ServiceId-5b9bf5c6-b42b-423b-a0ac-045ccb154d9e\",\n",
    "  \"instance_id\": \"12199dc8-c416-4bce-b27e-f3cde36d59ac\",\n",
    "  \"password\": \"296e26c3-fc25-47fe-8a88-1b4660ba81ed\",\n",
    "  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "  \"username\": \"065ebbd2-9b64-4479-b0fe-e6c1d9054cd1\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {wml_client.repository.ModelMetaNames.AUTHOR_NAME: \"Rich Tarro\", \n",
    "               wml_client.repository.ModelMetaNames.AUTHOR_EMAIL: \"mail@us.ibm.com\", \n",
    "               wml_client.repository.ModelMetaNames.NAME: \"RetailChurnXGBoost\"}\n",
    "\n",
    "published_model = wml_client.repository.store_model(model=model, meta_props=model_props,training_data=X_train, training_target=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IBM Logo](http://www-03.ibm.com/press/img/Large_IBM_Logo_TN.jpg)\n",
    "\n",
    "Rich Tarro  \n",
    "Anaytics Technical Specialist  \n",
    "email: rtarro@us.ibm.com\n",
    "    \n",
    "July 30, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 with Spark",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
